{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **AllenNLP demo**\n",
    "\n",
    "This is a demo for prediction venue based on title and abstract of the paper\n",
    "\n",
    "reference: https://github.com/allenai/allennlp-as-a-library-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'allennlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6b2ae605186f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# for dataset reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextField\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequenceLabelField\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabelField\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_readers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDatasetReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'allennlp'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Iterator, List, Dict, Optional\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# for dataset reader\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.fields import TextField, SequenceLabelField, LabelField\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token, Tokenizer, WordTokenizer\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "\n",
    "# read pretrained embedding from AWS S3\n",
    "from allennlp.modules.token_embedders.embedding import _read_embeddings_from_text_file\n",
    "\n",
    "# for building model\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.modules import FeedForward\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.nn import InitializerApplicator, RegularizerApplicator\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.training.trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create classes for the model**\n",
    "\n",
    "Generally, we need to implement 2 classes for AllenNLP including\n",
    "\n",
    "- `DatasetReader`: to read dataset and return `Instance` class\n",
    "- `Model`: input `Instance` class and return output prediction\n",
    "\n",
    "`Model` consists of the Sequence to Vector model (`Seq2Vec`)\n",
    "\n",
    "<img src=\"figures/bilstm.png\" width=\"300\"/>\n",
    "\n",
    "\n",
    "and we use the combination of vectors to predict venue\n",
    "\n",
    "<img src=\"figures/venue_prediction.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PublicationDatasetReader(DatasetReader):\n",
    "    \"\"\"\n",
    "    DatasetReader for publication and venue dataaet\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 tokenizer: Tokenizer = None,\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None, \n",
    "                 lazy: bool = False) -> None:\n",
    "        super().__init__(lazy)\n",
    "        self._tokenizer = tokenizer or WordTokenizer()\n",
    "        self._token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
    "\n",
    "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
    "        \"\"\"\n",
    "        Read publication and venue dataset in JSON format\n",
    "        \n",
    "        Data is in the following format:\n",
    "            {\"title\": ..., \"paperAbstract\": ..., \"venue\": ...}\n",
    "        \"\"\"\n",
    "        with open(cached_path(file_path), \"r\") as data_file:\n",
    "            for line in data_file:\n",
    "                line = line.strip(\"\\n\")\n",
    "                if not line:\n",
    "                    continue\n",
    "                paper_json = json.loads(line)\n",
    "                title = paper_json['title']\n",
    "                abstract = paper_json['paperAbstract']\n",
    "                venue = paper_json['venue']\n",
    "                yield self.text_to_instance(title, abstract, venue)\n",
    "        \n",
    "    def text_to_instance(self, \n",
    "                         title: str, \n",
    "                         abstract: str, \n",
    "                         venue: str=None) -> Instance:\n",
    "        \"\"\"\n",
    "        Turn title, abstract, and venue to instance\n",
    "        \"\"\"\n",
    "        tokenized_title = self._tokenizer.tokenize(title)\n",
    "        tokenized_abstract = self._tokenizer.tokenize(abstract)\n",
    "        title_field = TextField(tokenized_title, self._token_indexers)\n",
    "        abstract_field = TextField(tokenized_abstract, self._token_indexers)\n",
    "        fields = {'title': title_field, \n",
    "                  'abstract': abstract_field}\n",
    "        if venue is not None:\n",
    "            fields['label'] = LabelField(venue)\n",
    "        return Instance(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AcademicPaperClassifier(Model):\n",
    "    \"\"\"\n",
    "    Model to classify venue based on input title and abstract\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 vocab: Vocabulary,\n",
    "                 text_field_embedder: TextFieldEmbedder,\n",
    "                 title_encoder: Seq2VecEncoder,\n",
    "                 abstract_encoder: Seq2VecEncoder,\n",
    "                 classifier_feedforward: FeedForward,\n",
    "                 initializer: InitializerApplicator = InitializerApplicator(),\n",
    "                 regularizer: Optional[RegularizerApplicator] = None) -> None:\n",
    "        super(AcademicPaperClassifier, self).__init__(vocab, regularizer)\n",
    "        self.text_field_embedder = text_field_embedder\n",
    "        self.num_classes = self.vocab.get_vocab_size(\"labels\")\n",
    "        self.title_encoder = title_encoder\n",
    "        self.abstract_encoder = abstract_encoder\n",
    "        self.classifier_feedforward = classifier_feedforward\n",
    "        self.metrics = {\n",
    "                \"accuracy\": CategoricalAccuracy(),\n",
    "                \"accuracy3\": CategoricalAccuracy(top_k=3)\n",
    "        }\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "        initializer(self)\n",
    "    \n",
    "    def forward(self, \n",
    "                title: Dict[str, torch.LongTensor],\n",
    "                abstract: Dict[str, torch.LongTensor],\n",
    "                label: torch.LongTensor = None) -> Dict[str, torch.Tensor]:\n",
    "        \n",
    "        embedded_title = self.text_field_embedder(title)\n",
    "        title_mask = get_text_field_mask(title)\n",
    "        encoded_title = self.title_encoder(embedded_title, title_mask)\n",
    "\n",
    "        embedded_abstract = self.text_field_embedder(abstract)\n",
    "        abstract_mask = get_text_field_mask(abstract)\n",
    "        encoded_abstract = self.abstract_encoder(embedded_abstract, abstract_mask)\n",
    "\n",
    "        logits = self.classifier_feedforward(torch.cat([encoded_title, encoded_abstract], dim=-1))\n",
    "        class_probabilities = F.softmax(logits, dim=-1)\n",
    "        argmax_indices = np.argmax(class_probabilities.cpu().data.numpy(), axis=-1)\n",
    "        labels = [self.vocab.get_token_from_index(x, namespace=\"labels\") for x in argmax_indices]\n",
    "        output_dict = {\n",
    "            'logits': logits, \n",
    "            'class_probabilities': class_probabilities,\n",
    "            'predicted_label': labels\n",
    "        }\n",
    "        if label is not None:\n",
    "            loss = self.loss(logits, label)\n",
    "            for metric in self.metrics.values():\n",
    "                metric(logits, label)\n",
    "            output_dict[\"loss\"] = loss\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Read dataset**\n",
    "\n",
    "- `cached_path`: can cache the file locally\n",
    "- `BasicTextFieldEmbedder` takes a mapping from index names to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/train.jsonl\"\n",
    "validation_data_path = \"https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/dev.jsonl\"\n",
    "pretrained_file = \"https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PublicationDatasetReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = reader.text_to_instance(\"This is a great paper.\", \n",
    "                                   \"Indeed, this is a great paper of all time\", \n",
    "                                   \"Nature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15000it [00:35, 428.37it/s]\n",
      "2000it [00:04, 419.87it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = reader.read(cached_path(train_data_path))\n",
    "validation_dataset = reader.read(cached_path(validation_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17000/17000 [00:02<00:00, 6340.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# building vocabulary\n",
    "vocab = Vocabulary.from_instances(train_dataset + validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:04, 80881.50it/s] \n"
     ]
    }
   ],
   "source": [
    "# load pre-trained embedding\n",
    "embedding_matrix = _read_embeddings_from_text_file(file_uri=pretrained_file, \n",
    "                                                   embedding_dim=100, \n",
    "                                                   vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64247, 100])\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.size()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 100\n",
    "num_classes = len(vocab.get_index_to_token_vocabulary('labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding\n",
    "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'), \n",
    "                            embedding_dim=EMBEDDING_DIM,\n",
    "                            weight=embedding_matrix)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_title = PytorchSeq2VecWrapper(torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, \n",
    "                                                 batch_first=True, bidirectional=True))\n",
    "lstm_abstract = PytorchSeq2VecWrapper(torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, \n",
    "                                                    batch_first=True, bidirectional=True))\n",
    "feed_forward = torch.nn.Linear(2 * 2 * HIDDEN_DIM, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AcademicPaperClassifier(vocab,\n",
    "                                word_embeddings, \n",
    "                                lstm_title, \n",
    "                                lstm_abstract, \n",
    "                                feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = BucketIterator(batch_size=64, \n",
    "                          sorting_keys=[(\"abstract\", \"num_tokens\"), \n",
    "                                        (\"title\", \"num_tokens\")])\n",
    "iterator.index_with(vocab) # index with the created vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_dataset,\n",
    "    validation_dataset=validation_dataset,\n",
    "    patience=2,\n",
    "    num_epochs=5,\n",
    "    serialization_dir='output'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.0962 ||: 100%|██████████| 235/235 [40:56<00:00, 10.45s/it]  \n",
      "loss: 1.0874 ||: 100%|██████████| 32/32 [00:07<00:00,  4.16it/s]\n",
      "loss: 1.0858 ||: 100%|██████████| 235/235 [39:35<00:00, 10.11s/it]  \n",
      "loss: 1.0808 ||: 100%|██████████| 32/32 [00:05<00:00,  5.42it/s]\n",
      "loss: 1.0815 ||: 100%|██████████| 235/235 [39:27<00:00, 10.07s/it] \n",
      "loss: 1.0766 ||: 100%|██████████| 32/32 [00:05<00:00,  5.62it/s]\n",
      "loss: 1.0779 ||: 100%|██████████| 235/235 [45:42<00:00, 11.67s/it]  \n",
      "loss: 1.0725 ||: 100%|██████████| 32/32 [00:05<00:00,  5.63it/s]\n",
      "loss: 1.0742 ||: 100%|██████████| 235/235 [40:22<00:00, 10.31s/it]  \n",
      "loss: 1.0688 ||: 100%|██████████| 32/32 [00:05<00:00,  5.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 4,\n",
       " 'peak_cpu_memory_MB': 1412.108288,\n",
       " 'training_duration': '3:26:36.009762',\n",
       " 'training_start_epoch': 0,\n",
       " 'training_epochs': 4,\n",
       " 'epoch': 4,\n",
       " 'training_loss': 1.0742415935435194,\n",
       " 'training_cpu_memory_MB': 1412.108288,\n",
       " 'validation_loss': 1.0688360258936882,\n",
       " 'best_validation_loss': 1.0688360258936882}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Prediction**\n",
    "\n",
    "Lastly, we can also write the prediction class `PaperClassifierPredictor` which take input any `json_dict` and return the `Instance`. The AllenNLP will take care of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.common.util import JsonDict\n",
    "from allennlp.predictors.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperClassifierPredictor(Predictor):\n",
    "    \"\"\"\"\n",
    "    Predictor wrapper for the AcademicPaperClassifier\n",
    "    \"\"\"\n",
    "    def _json_to_instance(self, json_dict: JsonDict) -> Instance:\n",
    "        title = json_dict['title']\n",
    "        abstract = json_dict['paperAbstract']\n",
    "        instance = self._dataset_reader.text_to_instance(title=title, abstract=abstract)\n",
    "        return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = PaperClassifierPredictor(model, dataset_reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logits': [0.07398353517055511, 0.08393894135951996, -0.1481025218963623], 'class_probabilities': [0.35576409101486206, 0.35932356119155884, 0.2849124073982239], 'predicted_label': 'AI'}\n"
     ]
    }
   ],
   "source": [
    "prediction_output = predictor.predict_json(\n",
    "    {\n",
    "        \"title\": \"Know What You Don't Know: Unanswerable Questions for SQuAD\", \n",
    "        \"paperAbstract\": \"Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuAD 2.0, the latest version of the Stanford Question Answering Dataset (SQuAD). SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD 2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuAD 2.0 is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD 1.1 achieves only 66% F1 on SQuAD 2.0.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(prediction_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load model for prediction**\n",
    "\n",
    "Here, we trained the model and save it in `output` folder using \n",
    "\n",
    "```\n",
    "allennlp train example_training.json -s output --include-package venue\n",
    "```\n",
    "\n",
    "`venue` is a library that we created where we make AllenNLP as a library. We can load trained model (`model.tar.gz`) from `serialization_dir` (`output`) and use it to predict the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/Project_SC/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "from allennlp.models.archival import load_archive\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "from venue.venue_predictor import PaperClassifierPredictor\n",
    "from venue.venue_reader import PublicationDatasetReader\n",
    "from venue.venue_classifier import AcademicPaperClassifier\n",
    "\n",
    "archive = load_archive('output/model.tar.gz')\n",
    "venue_predictor = Predictor.from_archive(archive, 'venue_predictor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logits': [1.3005162477493286, 0.6157347559928894, -2.2390246391296387], 'class_probabilities': [0.6522191166877747, 0.3288491368293762, 0.018931739032268524], 'predicted_label': 'ACL'}\n"
     ]
    }
   ],
   "source": [
    "prediction_output = venue_predictor.predict_json(\n",
    "    {\n",
    "        \"title\": \"Know What You Don't Know: Unanswerable Questions for SQuAD\", \n",
    "        \"paperAbstract\": \"Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuAD 2.0, the latest version of the Stanford Question Answering Dataset (SQuAD). SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD 2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuAD 2.0 is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD 1.1 achieves only 66% F1 on SQuAD 2.0.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ACL', 1: 'AI', 2: 'ML'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "venue_predictor._model.vocab.get_index_to_token_vocabulary('labels') # all classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Predict which journals to submit from Medline**\n",
    "\n",
    "We  do a fun experiment where we train the same model to classify \n",
    "publications from sample 110 journals from MEDLINE. We got accuracy of 64.9 percent on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from allennlp.models.archival import load_archive\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "from venue.venue_predictor import PaperClassifierPredictor\n",
    "from venue.venue_reader import PublicationDatasetReader\n",
    "from venue.venue_classifier import AcademicPaperClassifier\n",
    "from allennlp.common.file_utils import cached_path\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1549312/791998690 [00:29<4:38:12, 47354.63B/s]"
     ]
    }
   ],
   "source": [
    "archive = load_archive(cached_path('https://s3-us-west-2.amazonaws.com/allennlp-tutorial/model.tar.gz'))\n",
    "venue_predictor = Predictor.from_archive(archive, 'venue_predictor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"\"\"\n",
    "Modeling peripheral visual acuity enables discovery of gaze strategies \n",
    "at multiple time scales during natural scene search\n",
    "\"\"\"\n",
    "abstract = \"\"\"\n",
    "Like humans, monkeys make saccades nearly three times a second. \n",
    "To understand the factors guiding this frequent decision, computational models of vision \n",
    "attempt to predict fixation locations using bottom-up visual features and top-down goals. \n",
    "How do the relative influences of these factors evolve over multiple time scales? \n",
    "Here we analyzed visual features at fixations using a retinal transform that provides realistic \n",
    "visual acuity by suitably degrading visual information in the periphery. \n",
    "In a task in which monkeys searched for a Gabor target in natural scenes, we characterized \n",
    "the relative importance of bottom-up and task-relevant influences by decoding fixated from \n",
    "nonfixated image patches based on visual features. At fast time scales, we found that search \n",
    "strategies can vary over the course of a single trial, with locations of higher saliency, target-similarity, \n",
    "edge–energy, and orientedness looked at later on in the trial. At slow time scales, we found that \n",
    "search strategies can be refined over several weeks of practice, and the influence of target orientation \n",
    "was significant only in the latter of two search tasks. Critically, these results were not observed without \n",
    "applying the retinal transform. Our results suggest that saccade-guidance strategies become apparent only \n",
    "when models take into account degraded visual representation in the periphery.'\n",
    "\"\"\"\n",
    "prediction_output = venue_predictor.predict_json(\n",
    "    {\n",
    "        \"title\": title, \n",
    "        \"paperAbstract\": abstract\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues = venue_predictor._model.vocab.get_index_to_token_vocabulary('labels') # all classes\n",
    "venues = [venues[i] for i in range(len(venues))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank top 5 which journal to submit\n",
    "sorted(list(zip(venues, prediction_output['class_probabilities'])), \n",
    "       key=lambda x: x[1], reverse=True)[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
